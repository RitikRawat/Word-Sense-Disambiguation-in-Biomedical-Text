{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cb3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "import numpy as np\n",
    "import itertools\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f0ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=[]\n",
    "with open('Additional Metaphors.txt', 'r') as f:\n",
    "     lines = f.readlines()\n",
    "     for line in lines:\n",
    "        terms.append(line.split('\\n')[0])\n",
    "terms = [(\" \" + x + \" \").lower() for x in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc82e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76811757",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Processed/\"\n",
    "files = Path(directory).glob('*.txt')\n",
    "files = list(files)\n",
    "top100 = list(itertools.islice(files, 0,100))\n",
    "zipped = list([top100[0:25],top100[25:50],top100[50:75],top100[75:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf2b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function3(files):    \n",
    "    term_freq ={}\n",
    "    for file in files:\n",
    "        name =  os.path.basename(file)\n",
    "        term_freq[name] = []\n",
    "        print(f'starting for {name}')\n",
    "        with open(file,'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                doclst = {}\n",
    "                m = line.split(' ',1)[1]\n",
    "                for word in terms:\n",
    "                    c = m.count(word)\n",
    "                    if c>0:\n",
    "                        doclst[word] = c\n",
    "                term_freq[name].append(doclst)           \n",
    "    return term_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11e085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting for 277.txtstarting for 361.txtstarting for 481.txtstarting for 12.txt\n",
      "\n",
      "\n",
      "\n",
      "starting for 138.txt\n",
      "starting for 279.txt\n",
      "starting for 417.txt\n",
      "starting for 406.txt\n",
      "starting for 501.txt\n",
      "starting for 160.txt\n",
      "starting for 370.txt\n",
      "starting for 152.txt\n",
      "starting for 44.txt\n",
      "starting for 533.txt\n",
      "starting for 459.txt\n",
      "starting for 294.txt\n",
      "starting for 95.txt\n",
      "starting for 15.txt\n",
      "starting for 78.txt\n",
      "starting for 488.txt\n",
      "starting for 457.txt\n",
      "starting for 228.txt\n",
      "starting for 36.txt\n",
      "starting for 245.txt\n",
      "starting for 382.txt\n",
      "starting for 425.txt\n",
      "starting for 486.txt\n",
      "starting for 254.txt\n",
      "starting for 183.txt\n",
      "starting for 69.txt\n",
      "starting for 321.txt\n",
      "starting for 353.txt\n",
      "starting for 192.txt\n",
      "starting for 155.txt\n",
      "starting for 31.txt\n",
      "starting for 38.txt\n",
      "starting for 422.txt\n",
      "starting for 293.txt\n",
      "starting for 385.txt\n",
      "starting for 143.txt\n",
      "starting for 354.txt\n",
      "starting for 205.txt\n",
      "starting for 270.txt\n",
      "starting for 112.txt\n",
      "starting for 285.txt\n",
      "starting for 534.txt\n",
      "starting for 506.txt\n",
      "starting for 522.txt\n",
      "starting for 71.txt\n",
      "starting for 242.txtstarting for 167.txt\n",
      "\n",
      "starting for 314.txt\n",
      "starting for 408.txt\n",
      "starting for 184.txt\n",
      "starting for 328.txt\n",
      "starting for 202.txt\n",
      "starting for 226.txt\n",
      "starting for 462.txt\n",
      "starting for 129.txt\n",
      "starting for 115.txt\n",
      "starting for 131.txt\n",
      "starting for 43.txt\n",
      "starting for 127.txt\n",
      "starting for 548.txt\n",
      "starting for 550.txt\n",
      "starting for 92.txt\n",
      "starting for 366.txt\n",
      "starting for 546.txt\n",
      "starting for 410.txt\n",
      "starting for 1.txt\n",
      "starting for 508.txt\n",
      "starting for 230.txtstarting for 474.txt\n",
      "\n",
      "starting for 8.txt\n",
      "starting for 302.txt\n",
      "starting for 368.txt\n",
      "starting for 169.txt\n",
      "starting for 67.txt\n",
      "starting for 253.txt\n",
      "starting for 120.txt\n",
      "starting for 450.txt\n",
      "starting for 6.txt\n",
      "starting for 195.txt\n",
      "starting for 144.txt\n",
      "starting for 326.txt\n",
      "starting for 541.txt\n",
      "starting for 473.txt\n",
      "starting for 525.txt\n",
      "starting for 305.txt\n",
      "starting for 282.txt\n",
      "starting for 237.txt\n",
      "starting for 401.txt\n",
      "starting for 60.txt\n",
      "starting for 419.txt\n",
      "starting for 377.txt\n",
      "starting for 76.txt\n",
      "starting for 379.txt\n",
      "starting for 313.txt\n",
      "starting for 465.txt\n",
      "starting for 239.txt\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=4) as exe:\n",
    "    results = exe.map(my_function3,zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "181a0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(results)\n",
    "term_freq = {**k[0],**k[1],**k[2],**k[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86824005",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_files = [os.path.basename(file) for file in top100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "341cbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mwe_100000.pkl', 'rb') as f:\n",
    "    top100000 = pickle.load(f)\n",
    "with open('tokens_final.pkl', 'rb') as f:\n",
    "    MWE = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "410b8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "mwe_dict = {}\n",
    "for key in top100000:\n",
    "    mwe_dict[key] = i\n",
    "    i=i+1\n",
    "\n",
    "i=0\n",
    "term_dict = {}\n",
    "for key in set(terms):\n",
    "    term_dict[key] = i\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b74bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((len(mwe_dict),len(term_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c27e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in my_files:\n",
    "    mwe_lst = MWE[file]\n",
    "    term_lst = term_freq[file]\n",
    "    for i in range(0,30000):\n",
    "        d1 = mwe_lst[i]\n",
    "        d2 = term_lst[i]\n",
    "        if (len(d1)>0 and len(d2)>0):\n",
    "            for mwe in d1:\n",
    "                if mwe in mwe_dict:\n",
    "                    for t in d2:\n",
    "                        matrix[mwe_dict[mwe],term_dict[t]] +=d1[mwe]*d2[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36c4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict_mwe = {mwe_dict[k]:k for k in mwe_dict.keys()}\n",
    "reverse_dict_terms = {term_dict[k]:k for k in term_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8fbf15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "with open('out.output_100000.tsv.I35', 'r') as f:\n",
    "     lines = f.readlines()\n",
    "     for line in lines:\n",
    "        clusters.append(line.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee2c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_cluster = {}\n",
    "for col in range(matrix.shape[1]):\n",
    "    arr = matrix[:,col]\n",
    "    term_cluster[reverse_dict_terms[col]] = []\n",
    "    for cluster in clusters:\n",
    "        s = 0\n",
    "        for mwe in cluster:\n",
    "            if mwe in mwe_dict:\n",
    "                if (arr[mwe_dict[mwe]]>2):\n",
    "                    s+=1\n",
    "        term_cluster[reverse_dict_terms[col]].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e4cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('term_cluster_add.pkl', 'wb') as f:\n",
    "    pickle.dump(term_cluster, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f45bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "for term in term_cluster:\n",
    "    lst =[]\n",
    "    for idx,elem in enumerate(term_cluster[term]):\n",
    "        lst.append(elem/len(clusters[idx]))\n",
    "    my_dict[term] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3da5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for term in my_dict:\n",
    "    lst=[]\n",
    "    for idx,elem in enumerate(my_dict[term]):\n",
    "        if elem >0.5:\n",
    "            lst.append(idx)\n",
    "    new_dict[term] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a88910ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for term in new_dict:\n",
    "    if len(new_dict[term])>1:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b386883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_dict ={}\n",
    "for term in term_cluster:\n",
    "    flag = False\n",
    "    for idx,elem in enumerate(term_cluster[term]):\n",
    "        if elem >=1:\n",
    "            flag =True\n",
    "    part_dict[term] = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeb1b906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for term in part_dict:\n",
    "    if ((part_dict[term] == True)):\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef76c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
